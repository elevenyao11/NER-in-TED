{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Corpus collection code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instruction for creating the entire corpus\n",
    "\n",
    "1. Import required libraries and packages\n",
    "2. Define functions\n",
    "3. Define variables and seeds. \n",
    "    - You can change the `languages` variable to collect parallel transcripts in languages of your interest. By default, the code collects parallel transcripts of English, Korean, and Chinese (simplified). \n",
    "    - You can increase the value of `NUM_DOCUMENTS` to increase the number of documents that you will collect (by default, it is 10).\n",
    "    - The current seed has two talks from TED.\n",
    "4. Run the cells to scrape the transcripts until you have collected a brown-size (or desired-size) corpus. \n",
    "5. All transcripts will be in `/transcripts/{language}/` folders."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step-by-step algorithm of the scraping code\n",
    "\n",
    "1. Check existing output files of English, and update the `done_list`\n",
    "2. Get `todo_talks` from `todo_list_files`\n",
    "3. while there are entries in `todo_talks` and `n` < `NUM_DOCUMENTS`:\n",
    "    - 3.1. Pull out current talk from `todo_talks`\n",
    "    - 3.2. Check if the current talk have the transcripts of all desired languages (default: ko, en, zh-cn)\n",
    "    - 3.3. while scraping does not succeed and until we try at least 10 times:\n",
    "        - 3.3.1. Try to scrape TED transcripts for each language. If this succeeds, change `success = True`. Also, get a list of related talks with respect to the current talk.\n",
    "        - 3.3.2. If there is an error, then try to sleep for one second and try again.\n",
    "    - 3.4. For talk in talks, if talk is not in the `done_list`, then add the talk in `todo_talks`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step-by-step of reading the paralleled transcripts in three languages.  \n",
    "1. Load the corpus by the `.load()` function.\n",
    "2. Get paralleled transcripts by `.transcripts`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code for building Ted talks corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports\n",
    "- These libraries/packages are required to be run all cells in this document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen\n",
    "import re\n",
    "import time\n",
    "import json\n",
    "import os\n",
    "import urllib.request as urllib2\n",
    "from nltk import pos_tag, sent_tokenize, word_tokenize\n",
    "import csv\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define functions for Ted_talks Class.\n",
    "- `get_profile` : Scrape transcripts given a soup object\n",
    "- `get_talks` : From one Ted Talk website, get more talks name from the recommend list\n",
    "- `get_talker`: From one Ted Talk website return talker's name\n",
    "- `get_views`: From one Ted Talk website return number of views\n",
    "- `get_date`: From one Ted Talk website return upload date\n",
    "- `update_csv`: Update the meta data to csv file\n",
    "- `write_json`: Update the json file from the talk dict scraped by ted talks websites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_profile(soup):\n",
    "    \"\"\"Return transcript from soup of Ted Talk website.\"\"\"\n",
    "    transcript = \"\"\n",
    "    for node in soup.find_all(\"div\", {\"class\" : \"Grid__cell flx-s:1 p-r:4\"}):\n",
    "        text = node.get_text().strip().replace('\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t', ' ')\n",
    "        if text:\n",
    "            transcript = transcript + '\\n' + \"[PARAGRAPH]\" + '\\n' + text\n",
    "    return transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_talks(soup):\n",
    "    \"\"\"From one Ted Talk website get more talks name from the recommend list\"\"\"\n",
    "    talks = []\n",
    "    regex = r\"slug\\\":\\\"((\\w+_)+\\w+)\\\"\"\n",
    "    for match in re.finditer(regex,str(soup)):\n",
    "        talks.append(match.group(1))\n",
    "    return talks[3:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_talker(soup):\n",
    "    \"\"\"From one Ted Talk website return talker's name\"\"\"\n",
    "    for node in soup.find_all(\"meta\", {\"name\" : \"author\"}):\n",
    "        name = node['content']\n",
    "    \n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_views(soup):\n",
    "    \"\"\"From one Ted Talk website return number of views\"\"\"\n",
    "    for node in soup.find_all(\"span\", {\"classname\" : \"f-w:400\"}):\n",
    "        views = node.parent.text.strip().split('\\n')[0]\n",
    "    \n",
    "    \n",
    "    return views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_date(soup):\n",
    "    \"\"\"From one Ted Talk website return upload date\"\"\"\n",
    "    \n",
    "    for node in soup.find_all(\"meta\", {\"itemprop\" : \"uploadDate\"}):\n",
    "        date = node['content'][:10]\n",
    "    \n",
    "    return date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_csv(talk_dict):\n",
    "    \"\"\"update the csv file\"\"\"\n",
    "    talk_dict.pop('text', None)\n",
    "    with open('../src/ted_talks.csv', 'a', newline='') as csvfile:\n",
    "        fieldnames = talk_dict.keys()\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "#         writer.writeheader()\n",
    "        writer.writerow(talk_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_json(talk_dict, file_path='../transcripts/en/ted_talks_en.json'): \n",
    "    \"\"\"Update the json file from the talk dict scraped by ted talks websites\"\"\"    \n",
    "    if os.path.exists(file_path):\n",
    "        with open(file_path, 'r', encoding='utf-8') as json_file:\n",
    "            temp = json.load(json_file)\n",
    "            if temp[-1]['title'] != talk_dict['title']:\n",
    "                temp.append(talk_dict)\n",
    "        with open(file_path, 'w', encoding='utf-8') as json_file:\n",
    "            json.dump(temp, json_file,  indent=4, separators=(',', ':'))\n",
    "            \n",
    "    else:\n",
    "        with open(file_path, 'a', encoding='utf-8') as json_file:\n",
    "            json.dump([talk_dict], json_file,  indent=4, separators=(',', ':'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Corpus Class\n",
    "\n",
    "#### NOTE\n",
    "**If you want to completely scrape from the beginning, make sure erase `todo.txt` file in the `/src/` folder, and all transcripts under the `/transcripts/` folder.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the TED talks corpus class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TED_Talks():\n",
    "    \n",
    "    def __init__(self, languages = ['en', 'ko', 'zh-cn']):\n",
    "        self.languages = languages\n",
    "        self.todo_list_file = \"todo.txt\"\n",
    "        self.done_list = set()\n",
    "        self.transcrpits = []\n",
    "        \n",
    "    def scrape(self, NUM_DOCUMENTS, seed_list = []):\n",
    "        \"\"\"Scrape ted talks transcripts from seed list. \"\"\"\n",
    "        \n",
    "        todo_talks = seed_list\n",
    "        \n",
    "        # check exist output file of english, update the done_list\n",
    "        file_path = f\"../transcripts/{self.languages[0]}/ted_talks_{self.languages[0]}.json\"\n",
    "        if os.path.exists(file_path):\n",
    "            f = open(file_path,encoding=\"utf-8\")\n",
    "            file = json.load(f)\n",
    "            for talk in file:\n",
    "                self.done_list.add(talk['title'])\n",
    "            f.close()\n",
    "\n",
    "        # get todo_talks from todo_list_file            \n",
    "        if os.path.exists(self.todo_list_file):\n",
    "            f = open(todo_list_file,encoding=\"utf-8\")\n",
    "            todo_talks = set(json.load(f))\n",
    "            f.close()\n",
    "            \n",
    "            \n",
    "        n = 0\n",
    "        while todo_talks and n < NUM_DOCUMENTS:\n",
    "            n+=1\n",
    "            current_talk = todo_talks.pop()\n",
    "            print(current_talk)\n",
    "            print(len(todo_talks))\n",
    "            print(len(self.done_list))\n",
    "            success = False\n",
    "            count = 0\n",
    "\n",
    "            # check if the talks have the transcrpits of all languages\n",
    "            exist_websites = 1 \n",
    "            for language in self.languages:\n",
    "                try: # need to open with try\n",
    "                    page = urlopen(f'https://www.ted.com/talks/{current_talk}/transcript?language={language}')\n",
    "                except urllib2.HTTPError as e:\n",
    "                    if e.getcode() == 404: # check the return code\n",
    "                        exist_websites = 0 # if no transcrpit in some language, set 0\n",
    "                time.sleep(1)\n",
    "\n",
    "            if exist_websites == 0:\n",
    "                print(\"no target languages\")\n",
    "                continue\n",
    "\n",
    "            # scrape the transcrpt and update the file.\n",
    "            while not success and count < 10:\n",
    "                try:\n",
    "                    \n",
    "                    talk_link = f'https://www.ted.com/talks/{current_talk}/transcript'\n",
    "                    name = get_talker(BeautifulSoup(urlopen(talk_link), 'html.parser'))\n",
    "                    \n",
    "                    for language in languages:\n",
    "                        # get meta data of the talk\n",
    "                        file_path = f\"../transcripts/{language}/ted_talks_{language}.json\"\n",
    "                        url = f\"{talk_link}?language={language}\"\n",
    "                        ted_soup = BeautifulSoup(urlopen(url), 'html.parser')\n",
    "                        \n",
    "                        # get meta data\n",
    "                        name = get_talker(ted_soup)\n",
    "                        text = get_profile(ted_soup)\n",
    "                        text_length = len(text)\n",
    "                        talks = get_talks(ted_soup)\n",
    "                        views = get_views(ted_soup)\n",
    "                        date = get_date(ted_soup)\n",
    "                        talk_dict = {'title':current_talk, 'talker':name, 'text_length':text_length, 'views':views, 'language':language, 'text':text, 'url':url}\n",
    "#                         print(talk_dict['talker'])\n",
    "                        write_json(talk_dict, file_path)\n",
    "                        update_csv(talk_dict)\n",
    "\n",
    "                        time.sleep(1)\n",
    "                        \n",
    "                    self.done_list.add(current_talk)    \n",
    "                     \n",
    "                    success = True\n",
    "                except:\n",
    "                    print(count, \" fail!\")\n",
    "                    count += 1\n",
    "                    time.sleep(1)\n",
    "            if count == 10:\n",
    "                continue\n",
    "            \n",
    "            # update the todo list.\n",
    "            for talk in talks:\n",
    "                if talk not in self.done_list:\n",
    "                    todo_talks.add(talk)\n",
    "            fout = open(self.todo_list_file,\"w\")\n",
    "            json.dump(list(todo_talks),fout)\n",
    "            fout.close()\n",
    "            done_list.add(current_talk)\n",
    "            time.sleep(1)\n",
    "            \n",
    "    def load(self):\n",
    "        \"\"\"Load the scraped json files\"\"\"\n",
    "        \n",
    "        title2ind_en = defaultdict(int)\n",
    "        title2ind_ko = defaultdict(int)\n",
    "        title2ind_cn = defaultdict(int)\n",
    "\n",
    "\n",
    "        file_path = f\"../transcripts/en/ted_talks_en.json\"\n",
    "        f = open(file_path,encoding=\"utf-8\")\n",
    "        file_en = json.load(f)\n",
    "        for i in range(len(file_en)):\n",
    "            title2ind_en[file_en[i]['title']] = i\n",
    "\n",
    "\n",
    "        file_path = f\"../transcripts/zh-cn/ted_talks_zh-cn.json\"\n",
    "        f = open(file_path,encoding=\"utf-8\")\n",
    "        file_cn = json.load(f)\n",
    "        for i in range(len(file_cn)):\n",
    "            title2ind_cn[file_cn[i]['title']] = i\n",
    "\n",
    "        file_path = f\"../transcripts/ko/ted_talks_ko.json\"\n",
    "        f = open(file_path,encoding=\"utf-8\")\n",
    "        file_ko = json.load(f)\n",
    "        for i in range(len(file_ko)):\n",
    "            title2ind_ko[file_ko[i]['title']] = i\n",
    "\n",
    "        share_titles = set(title2ind_en).intersection(set(title2ind_ko)).intersection((set(title2ind_cn)))\n",
    "\n",
    "        for title in share_titles:\n",
    "            text_lst = []\n",
    "            text_lst.append(file_en[title2ind_en[title]]['text'])\n",
    "            text_lst.append(file_ko[title2ind_ko[title]]['text'])\n",
    "            text_lst.append(file_cn[title2ind_cn[title]]['text'])\n",
    "\n",
    "            self.transcrpits.append(text_lst)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create an instance of Ted_talks class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "ted_talks = TED_Talks()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the scraped json files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "ted_talks.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scrape the Ted Talks transcripts\n",
    "- Change the value of `NUM_DOCUMENTS` to scrape the number of documnets of your interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables\n",
    "NUM_DOCUMENTS = 10\n",
    "languages = ['en', 'ko', 'zh-cn']\n",
    "todo_list_file = \"todo.txt\"\n",
    "\n",
    "# set seeds\n",
    "seed_list = set([\"elizabeth_hellmuth_margulis_why_we_love_repetition_in_music\", \"anita_collins_how_playing_an_instrument_benefits_your_brain\"])\n",
    "\n",
    "# uncomment below to start scrape\n",
    "# ted_talks.scrape(NUM_DOCUMENTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To Stop and To Continue Scraping\n",
    "\n",
    "Every time the scraped transcripts reach the number of documents that you set in `NUM_DOCUMNETS`, or the scraping code has stopped due to an unexpected error such as kernel interruption, computer shutdown, or network issues, the **to do list** will be saved as `todo.txt` in the `src` folder, and the transcripts will be saved in the `transcripts` folder. \n",
    "\n",
    "If you run the code above (`ted_talks.scrape(NUM_DOCUMENTS)`), it will continue scraping transcripts from the top talk in `todo.txt`. The transcripts will be appended to the existing transcripts, updating the `done_list`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the paralleled transcrpits from corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n[PARAGRAPH]\\nIt\\'s 4 a.m., \\nand the big test is in eight hours,\\n followed by a piano recital.\\n You\\'ve been studying and playing for days,\\nbut you still don\\'t feel ready for either.\\n So, what can you do?\\n Well, you can drink another cup of coffee\\n and spend the next few hours \\ncramming and practicing,\\n but believe it or not,\\n you might be better off closing the books,\\nputting away the music,\\n and going to sleep.\\n[PARAGRAPH]\\nSleep occupies nearly \\na third of our lives,\\n but many of us give surprisingly\\nlittle attention and care to it.\\n This neglect is often the result \\nof a major misunderstanding.\\n Sleep isn\\'t lost time,\\n or just a way to rest \\nwhen all our important work is done.\\n Instead, it\\'s a critical function,\\n during which your body balances\\nand regulates its vital systems,\\n affecting respiration\\n and regulating everything from circulation\\nto growth and immune response.\\n[PARAGRAPH]\\nThat\\'s great, but you can worry about \\nall those things after this test, right?\\n Well, not so fast.\\n It turns out that sleep \\nis also crucial for your brain,\\n with a fifth of your body\\'s \\ncirculatory blood\\n being channeled to it as you drift off.\\n And what goes on \\nin your brain while you sleep\\n is an intensely active period \\nof restructuring\\n that\\'s crucial for how our memory works.\\n[PARAGRAPH]\\nAt first glance,\\n our ability to remember things \\ndoesn\\'t seem very impressive at all.\\n 19th century psychologist \\nHerman Ebbinghaus\\n demonstrated that we normally forget\\n40% of new material\\n within the first twenty minutes,\\n a phenomenon known\\nas the forgetting curve.\\n[PARAGRAPH]\\nBut this loss can be prevented \\nthrough memory consolidation,\\n the process by which\\ninformation is moved\\n from our fleeting short-term memory\\nto our more durable long-term memory.\\n[PARAGRAPH]\\nThis consolidation occurs with the help\\nof a major part of the brain,\\n known as the hippocampus.\\n Its role in long-term memory formation\\n was demonstrated in the 1950s\\nby Brenda Milner\\n in her research with \\na patient known as H.M.\\n After having his hippocampus removed,\\n H.M.\\'s ability to form new short-term memories\\nwas damaged,\\n but he was able to learn physical tasks\\nthrough repetition.\\n Due to the removal of his hippocampus,\\n H.M.\\'s ability to form long-term memories\\nwas also damaged.\\n What this case revealed,\\namong other things,\\n was that the hippocampus \\nwas specifically involved\\n in the consolidation of\\nlong-term declarative memory,\\n such as the facts and concepts\\nyou need to remember for that test,\\n rather than procedural memory,\\n such as the finger movements\\nyou need to master for that recital.\\n[PARAGRAPH]\\nMilner\\'s findings, along with work \\nby Eric Kandel in the 90\\'s,\\n have given us our current model \\nof how this consolidation process works.\\n Sensory data is initially transcribed\\n and temporarily recorded in the neurons\\nas short-term memory.\\n From there, it travels to the hippocampus,\\n which strengthens and enhances \\nthe neurons in that cortical area.\\n Thanks to the phenomenon\\nof neuroplasticity,\\n new synaptic buds are formed,\\nallowing new connections between neurons,\\n and strengthening the neural network\\n where the information will be returned\\nas long-term memory.\\n[PARAGRAPH]\\nSo why do we remember\\nsome things and not others?\\n Well, there are a few ways to influence\\n the extent and effectiveness \\nof memory retention.\\n For example, memories that are formed\\nin times of heightened feeling,\\n or even stress,\\n will be better recorded due to \\nthe hippocampus\\' link with emotion.\\n But one of the major factors contributing\\nto memory consolidation is,\\n you guessed it,\\n a good night\\'s sleep.\\n[PARAGRAPH]\\nSleep is composed of four stages,\\n the deepest of which are known\\nas slow-wave sleep\\n and rapid eye movement.\\n EEG machines monitoring\\npeople during these stages\\n have shown electrical impulses\\n moving between the brainstem,\\nhippocampus, thalamus, and cortex,\\n which serve as relay stations \\nof memory formation.\\n And the different stages of sleep\\nhave been shown to help consolidate\\n different types of memories.\\n[PARAGRAPH]\\nDuring the non-REM slow-wave sleep,\\n declarative memory is encoded \\ninto a temporary store\\n in the anterior part of the hippocampus.\\n Through a continuing dialogue \\nbetween the cortex and hippocampus,\\n it is then repeatedly reactivated,\\n driving its gradual redistribution\\nto long-term storage in the cortex.\\n REM sleep, on the other hand, with\\nits similarity to waking brain activity,\\n is associated with the consolidation\\nof procedural memory.\\n So based on the studies,\\n going to sleep three hours after \\nmemorizing your formulas\\n and one hour after practicing your scales\\nwould be the most ideal.\\n[PARAGRAPH]\\nSo hopefully you can see now\\nthat skimping on sleep\\n not only harms your long-term health,\\n but actually makes it less likely\\n that you\\'ll retain all that knowledge\\nand practice from the previous night,\\n all of which just goes to affirm\\nthe wisdom of the phrase, \"Sleep on it.\"\\n When you think about \\nall the internal restructuring\\n and forming of new connections\\nthat occurs while you slumber,\\n you could even say that proper sleep\\n will have you waking up every morning\\nwith a new and improved brain,\\n ready to face the challenges ahead.',\n",
       " '\\n[PARAGRAPH]\\n새벽 4시입니다.\\n 8시간 후에 중요한 시험이 있죠.\\n 곧이어 피아노 연주회도 있군요.\\n 당신은 며칠 내내 시험공부와 피아노 연습을 해왔습니다.\\n하지만, 어느 것도 준비되지 않은 기분입니다.\\n 그렇다면, 당신은 무엇을 할 수 있을까요?\\n 음, 커피를 한 잔 더 마실 수 있을 겁니다.\\n 그리고 이후 몇 시간 동안 벼락공부와 피아노 연습을 하는 거죠.\\n 하지만, 믿기 어렵더라도\\n 공부하던 책을 덮고 피아노 악보를 치운 후\\n 잠을 자는 편이 나을지도 모릅니다.\\n[PARAGRAPH]\\n수면은 거의 우리 생애의 3분의 1을 차지합니다.\\n 하지만, 대부분의 사람들은 놀라울 정도로\\n수면에 관심이 거의 없고 신경도 쓰지 않습니다.\\n 이러한 소홀함은 종종 심각한 오해에서 비롯합니다.\\n 수면은 시간 낭비가 아닙니다.\\n 또는 중요한 일을 끝내고 휴식을 취하는 것만이 아닙니다.\\n 대신에, 매우 중요한 의식이죠.\\n 당신은 수면 중에 신체의 균형을 잡고 중요한 신체 시스템을 조정합니다.\\n 이는 호흡에 영향을 미치고,\\n 순환부터 성장과 면역반응까지 모든 것을 조정합니다.\\n[PARAGRAPH]\\n엄청난 일이죠. 하지만 이런 것은 시험이 끝난 후에나 걱정할 일이라고요?\\n 잠시만, 더 들어보세요.\\n 수면은 뇌에도 매우 중요하다고 알려져 있습니다.\\n 당신이 잠이 들면 순환 중인 혈액의 5분의 1이\\n 뇌로 흘러갑니다.\\n 당신은 잠자고 있는 동안\\n 몹시 활발하게 뇌의 내부를 재구성하고 있는 거죠.\\n 이는 우리의 기억이 어떻게 작용하느냐에 결정적입니다.\\n[PARAGRAPH]\\n언뜻 보기에는\\n 어떤 것을 기억하는 능력은 전혀 대단한 것 같지 않습니다.\\n 19세기 심리학자 헤르만 에빙하우스는\\n 사람은 보통 새롭게 배운 내용의 40%를\\n\\n 처음 20분 내에 잊어버린다고 설명했습니다.\\n 이러한 현상을 망각곡선이라고 합니다.\\n[PARAGRAPH]\\n하지만 이러한 기억 손실은 기억의 응고화를 통해 방지할 수 있습니다.\\n 기억의 응고화는 정보가 찰나의 단기기억에서\\n 보다 지속적인 장기기억으로 전달되는 과정입니다.\\n[PARAGRAPH]\\n이러한 응고화는 뇌의 중요 부위를 통해 일어나는데\\n 이 부위를 해마라고 합니다.\\n 장기기억 형성에 있어서 해마의 기능은\\n 1950년대에 브렌다 밀너가\\n H.M.이라고 알려진 환자에 대한 연구를 통해 보고하였습니다.\\n 환자는 해마가 제거된 이후\\n 새로운 단기기억을 생성하는 기능에 손상을 입었습니다.\\n 하지만 신체적인 활동은 반복을 통해 학습이 가능했습니다.\\n 환자는 해마 제거로 인해\\n 장기기억을 생성하는 능력 또한 손상을 입었죠.\\n 이러한 사례는 다른 무엇보다도\\n 해마가 절차기억보다는\\n 장기 서술기억의 응고화에 특히 관여한다는 것을 보여줍니다.\\n 시험 때문에 암기하는 사실들과 개념들 같은 것 말이죠.\\n 반면에 절차기억은\\n 연주회를 위해 숙달해야 하는 손가락 움직임과 같은 것입니다.\\n[PARAGRAPH]\\n밀너의 발견은, 90년대 에릭 캔들의 연구와 더불어\\n 기억의 응고화 과정을 설명하는 현재의 모형을 제시했습니다.\\n 감각데이터가 처음 입력되면,\\n 단기기억으로서 신경세포에 일시적으로 기록됩니다.\\n 단기기억은 신경세포에서부터 해마를 향해 이동하는데\\n 이는 대뇌피질의 신경세포를 강화하고 향상시킵니다.\\n 뇌의 신경가소성 현상 덕분에\\n 새로운 시냅스 돌기가 나와서 신경세포 사이를 새로 연결하고\\n 신경세포망을 강화할 수 있는데,\\n 이 곳에서 정보가 장기기억이 되어 돌아옵니다.\\n[PARAGRAPH]\\n그럼 우리는 왜 어떤 것은 기억하고 다른 것은 기억하지 못할까요?\\n 기억 보존의 정도와 유효성에\\n 영향을 미치는 몇 가지 조건이 있습니다.\\n 예를 들어, 감정이 고조되었거나\\n 스트레스 받을 때 생성된 기억은\\n 해마의 감정과의 연결로 인해 보다 잘 기록됩니다.\\n 하지만 기억의 응고화에 기여하는 주요 요인 중 하나는\\n 예상했겠지만\\n 잠을 잘 자는 것입니다.\\n[PARAGRAPH]\\n수면은 4개의 단계로 이루어졌습니다.\\n 가장 깊은 수면은 서파수면과\\n 렘(REM)수면으로 알려져 있죠.\\n 이러한 수면단계 동안의 뇌파검사 결과를 보면\\n 전기자극이\\n 뇌간, 해마, 시상 그리고 대뇌피질 사이를 이동합니다.\\n 이들은 기억형성의 중계국 역할을 하죠.\\n 그리고 각 수면단계는\\n 각기 다른 유형의 기억을 응고화하는데 도움을 줍니다.\\n[PARAGRAPH]\\n비렘수면인 서파수면 동안은\\n 서술적 기억이 일시적 저장소에 담깁니다.\\n 이 저장소는 해마 앞쪽 부분에 있습니다.\\n 대뇌피질과 해마 간의 끊임없는 대화를 통해\\n 기억은 반복적으로 재활성화되어\\n 대뇌피질의 장기기억 저장소에 서서히 재분배됩니다.\\n 반면에, 뇌가 활발하게 활동하는 상태와 유사한 렘수면은\\n 절차기억의 응고화와 관련이 있습니다.\\n 따라서 이러한 연구결과을 토대로 하면\\n 공부한 공식을 암기한 후에는 3시간 동안 잠을 자고\\n 연주 연습 후에는 1시간동안 자는 것이 가장 이상적일 것입니다.\\n[PARAGRAPH]\\n이제 당신도 이해했겠죠.\\n\\n 잠을 너무 안 자면 장기적으로 건강을 해칠 뿐만 아니라\\n 그 전날 밤에 공부하고 연습한 것을\\n 유지하는 것도 쉽지 않다는 것을 말입니다.\\n \"일단 자고 나서 생각하자\"라는 말이 현명한 것이죠.\\n 당신이 자고 있는 동안 일어나는\\n 체내의 재구성과 새로운 연결형성을 생각하면\\n 당신은 잠을 제대로 잔 것만으로도\\n 매일 아침 뇌를 새롭게 개선했다고 말할 수도 있습니다.\\n 다가온 도전에 맞설 준비가 된 것이죠.',\n",
       " '\\n[PARAGRAPH]\\n『音乐』\\n 现在是凌晨四点，\\n 八小时之后你有一场重要的考试，\\n 接着还有一场钢琴独奏会。\\n 你已经连日学习和苦练钢琴，\\n 但你仍觉得你还未准备好。\\n 那么你能做些什么呢？\\n 你可以再喝一杯咖啡，\\n 并在仅剩的一点时间里继续奋战，\\n 但是你也许不相信，\\n 如果你关上书本，停止练习\\n 并去睡一觉， 效果会更好。\\n[PARAGRAPH]\\n睡眠几乎占据了我们生命的三分之一，\\n 可令人惊讶的是，\\n许多人并不关心他们的睡眠。\\n 人们对睡眠的忽视\\n往往是来自于一个很大的误解。\\n 睡觉并不是浪费时间，\\n 睡眠也不仅仅是工作后的休息，\\n 相反，睡眠是一个很关键的过程，\\n 睡眠期间，你的身体会对各系统进行调节，\\n 你的呼吸系统会受到影响，\\n 血液循环系统、免疫系统\\n与身体的成长都会受到影响。\\n[PARAGRAPH]\\n听起来很棒，但你可以等考完试以后\\n再来担心睡眠，对吧？\\n 先别这么快下结论。\\n 原来睡眠对你的大脑也至关重要，\\n 在你进入梦乡的时候，你身体里\\n五分之一的血液都会流入到你的大脑。\\n 你睡觉的时间正是你的大脑\\n 内部重新调整组合的时间，\\n 这个阶段对我们的记忆功能十分重要。\\n[PARAGRAPH]\\n乍一看，\\n 我们的记忆能力并不值得惊叹，\\n 十九世纪的心理学家，赫尔曼·艾宾浩斯发现\\n 一般在20分钟内我们会忘记40%的新事物，\\n 这个现象被称作“遗忘曲线”。\\n[PARAGRAPH]\\n可是记忆力可以通过对记忆的巩固来提高，\\n 在这个巩固的过程中，新的事物会从短期记忆\\n 移到更稳定的长期记忆。\\n[PARAGRAPH]\\n记忆巩固得益于脑部的一个重要部位，\\n 这个部位被称为海马体，\\n 海马体在长期记忆形成中扮演的角色\\n 于1950年代被布兰达·米尔内\\n 通过她对一位名为H.M.的病人的研究证实。\\n H.M.的海马体被移除后，\\n 他形成新的短期记忆的能力遭到破坏，\\n 但他仍能够通过\\n不断重复学习新的体能任务。\\n 由于海马体的移除，\\n H.M形成长期记忆的能力也被破坏了。\\n 这个例子反映出\\n 海马体在长期陈述性记忆\\n而非程序性记忆巩固的过程中至关重要，\\n 陈述性记忆包括你考试要记的事实、概念等，\\n 程序性记忆包括\\n你钢琴独奏要记住的手指动作。\\n[PARAGRAPH]\\n米尔内的发现，加上\\n埃里克·坎德尔在90年代的发现\\n 给我们提供了这个巩固过程的现有模型。\\n 感官数据会先被暂时\\n转录到短期记忆的神经元上面，\\n 再进入到海马体，\\n 而海马体再将其皮质区的神经元进行强化。\\n 多亏了这一神经可塑性，\\n 新的突触芽得以形成\\n并在神经元之间建立新的连接，\\n 从而强化相应神经网络\\n 并形成长期记忆。\\n[PARAGRAPH]\\n为什么我们会记住一些而忘掉另一些？\\n 那是因为有很多东西会影响\\n 记忆形成的程度和有效性。\\n 比如，那些在情感或\\n压力强烈的时候形成的记忆\\n 会更容易被记录下来\\n因为海马体和情感之间的关联。\\n 但是一个影响记忆巩固的重要因素是，\\n 你已经猜到了，\\n 就是一晚好的睡眠。\\n[PARAGRAPH]\\n睡眠有四个阶段组成，\\n 最深的就是慢波睡眠\\n 和快速眼动睡眠。\\n 脑电图监测结果显示在这些阶段\\n 电脉冲在脑干、海马体、\\n丘脑和大脑皮层间移动，\\n 而这些都是记忆形成的中转站。\\n 不同的睡眠阶段有助于巩固\\n 不同类型的记忆。\\n[PARAGRAPH]\\n在非快速眼动慢波睡眠阶段，\\n 陈述性记忆被暂时放在\\n 海马体的前部。\\n 通过大脑皮层和海马体的不断对话，\\n 这些记忆反复被激活，\\n 使得它们慢慢转到大脑皮层的\\n长期记忆存储区域。\\n 同时， 快速眼动睡眠，\\n跟大脑醒着的时候相似，\\n 跟程序性记忆的巩固有关。\\n 基于这些研究，\\n 在你背公式三个小时后，\\n 练习钢琴一个小时后进入睡眠是最好的。\\n[PARAGRAPH]\\n希望你现在已经明白牺牲睡眠\\n 不仅对你的长期健康有害，\\n 而且会影响\\n 你记住前晚的知识和练习的能力，\\n 这些都证明了这句话的智慧\\n——先睡一觉再说。\\n 想一下你睡觉的时候，\\n 你的大脑在忙着重组、形成新连接等，\\n 你甚至可以说，\\n 好的睡眠让你第二天\\n有一个全新的更好的大脑，\\n 准备迎接新的挑战。']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ted_talks.transcrpits[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
