{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "stable-script",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "from collections import Counter\n",
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "absolute-architecture",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = f\"../transcripts/en/ted_talks_en.json\"\n",
    "f = open(file_path,encoding=\"utf-8\")\n",
    "file_en = json.load(f)\n",
    "f.close()\n",
    "file_path = f\"../transcripts/zh-cn/ted_talks_zh-cn.json\"\n",
    "f = open(file_path,encoding=\"utf-8\")\n",
    "file_cn = json.load(f)\n",
    "f.close()\n",
    "file_path = f\"../transcripts/ko/ted_talks_ko.json\"\n",
    "f = open(file_path,encoding=\"utf-8\")\n",
    "file_ko = json.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "persistent-nashville",
   "metadata": {},
   "source": [
    "### Create annotated json corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "greek-richardson",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text(text):\n",
    "    paras = text.replace(\"\\n\", \" \").strip(\" \").replace(\"  \", \" \").split(\"[PARAGRAPH]\")\n",
    "    \n",
    "    return [para.strip(\" \") for para in paras if len(para) > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "strong-jacob",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_corpus = pd.DataFrame(file_en)\n",
    "en_corpus[\"text\"] = en_corpus[\"text\"].apply(process_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "consolidated-regulation",
   "metadata": {},
   "outputs": [],
   "source": [
    "ko_corpus = pd.DataFrame(file_ko)\n",
    "ko_corpus[\"text\"] = ko_corpus[\"text\"].apply(process_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "acute-contractor",
   "metadata": {},
   "outputs": [],
   "source": [
    "cn_corpus = pd.DataFrame(file_cn)\n",
    "cn_corpus[\"text\"] = cn_corpus[\"text\"].apply(process_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "respective-input",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_corpus_to_list(corpus):\n",
    "    return corpus.apply(lambda x:x.to_dict(), axis=1).to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "unnecessary-voice",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_json(corpus, file_path):\n",
    "    with open(file_path, 'w', encoding='utf-8') as json_file:\n",
    "        json.dump(corpus, json_file,  indent=4, separators=(',', ':'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "headed-deficit",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_named_entity(talk):\n",
    "    paras = []\n",
    "    \n",
    "    for para in talk:\n",
    "        doc = nlp(para)\n",
    "        ne_lex = {}\n",
    "        ents = []\n",
    "        ne_lex[\"text\"] = para            \n",
    "        for ent in doc.ents:\n",
    "            ent_lex = {}\n",
    "            ent_lex[\"start\"] = ent.start_char\n",
    "            ent_lex[\"end\"] = ent.end_char\n",
    "            ent_lex[\"text\"] = ent.text\n",
    "            ent_lex[\"label\"] = ent.label_\n",
    "            ents.append(ent_lex)\n",
    "        ne_lex[\"ents\"] = ents\n",
    "        paras.append(ne_lex)\n",
    "    \n",
    "    return paras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "romantic-archive",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_paragraph(talk):\n",
    "    paras = []\n",
    "    \n",
    "    for para in talk:\n",
    "        ne_lex = {}\n",
    "        ents = []\n",
    "        ne_lex[\"text\"] = para\n",
    "        ne_lex[\"ents\"] = ents\n",
    "        paras.append(ne_lex)\n",
    "    \n",
    "    return paras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "expanded-party",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_corpus[\"text\"] = en_corpus[\"text\"].apply(extract_named_entity)\n",
    "ko_corpus[\"text\"] = ko_corpus[\"text\"].apply(extract_paragraph)\n",
    "cn_corpus[\"text\"] = cn_corpus[\"text\"].apply(extract_paragraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "thrown-amendment",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_corpus_list = convert_corpus_to_list(en_corpus)\n",
    "ko_corpus_list = convert_corpus_to_list(ko_corpus)\n",
    "cn_corpus_list = convert_corpus_to_list(cn_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "offensive-algeria",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_file_path = \"../transcripts/en/annotated/annotated_ted_talks_en.json\"\n",
    "ko_file_path = \"../transcripts/ko/annotated/annotated_ted_talks_ko.json\"\n",
    "cn_file_path = \"../transcripts/zh-cn/annotated/annotated_ted_talks_cn.json\"\n",
    "write_json(en_corpus_list, en_file_path)\n",
    "write_json(ko_corpus_list, ko_file_path)\n",
    "write_json(cn_corpus_list, cn_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worst-ridge",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
